{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raghavashok24/nexusai_research_raghav/blob/main/updated_complete_EWS_nexusai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMRegressor\n",
        "import shap\n",
        "import optuna\n",
        "import io\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from xgboost import XGBRegressor\n",
        "from google.colab import files\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.base import clone\n",
        "from scipy.stats import spearmanr\n",
        "from matplotlib.colors import ListedColormap"
      ],
      "metadata": {
        "id": "Msb4GcU7SPAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file upload\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(io.BytesIO(uploaded[filename]))"
      ],
      "metadata": {
        "id": "sdXzbC6fSXhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "target_col = 'probabilistic_risk_score'\n",
        "flag_cols = [col for col in df.columns if 'was_imputed' in col.lower()]\n",
        "exclude_from_model = ['num_thresholds_exceeded'] + flag_cols\n",
        "\n",
        "# Drop non-predictive metadata\n",
        "non_predictive = ['Bank_Name', 'State', 'Region', 'QuarterLabel']\n",
        "df.drop(columns=[col for col in non_predictive if col in df.columns], inplace=True)\n",
        "\n",
        "# Time-based split\n",
        "df_sorted = df.sort_values(by='Quarter').reset_index(drop=True)\n",
        "split_point = int(df_sorted['Quarter'].max() * 0.8)\n",
        "\n",
        "train_df = df_sorted[df_sorted['Quarter'] <= split_point].copy()\n",
        "test_df = df_sorted[df_sorted['Quarter'] > split_point].copy()\n",
        "\n",
        "# Target variable\n",
        "y_train = train_df[target_col]\n",
        "y_test = test_df[target_col]\n",
        "\n",
        "# X variables (masking num_thresholds_exceeded & flags from both train/test)\n",
        "X_train = train_df.drop(columns=[target_col] + exclude_from_model, errors='ignore')\n",
        "X_test = test_df.drop(columns=[target_col] + exclude_from_model, errors='ignore')"
      ],
      "metadata": {
        "id": "HGCKGzIbSaZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lightgbm baseline model\n",
        "baseline_lgb = LGBMRegressor(random_state=42)\n",
        "baseline_lgb.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "baseline_preds = baseline_lgb.predict(X_test)\n",
        "\n",
        "baseline_mse = mean_squared_error(y_test, baseline_preds)\n",
        "baseline_r2 = r2_score(y_test, baseline_preds)\n",
        "baseline_brier = baseline_mse\n",
        "\n",
        "print(\"=== Baseline LightGBM ===\")\n",
        "print(f\"MSE: {baseline_mse:.4f}\")\n",
        "print(f\"R²: {baseline_r2:.4f}\")\n",
        "print(f\"Adapted Brier Score: {baseline_brier:.4f}\")"
      ],
      "metadata": {
        "id": "VnPDjbOJScU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optuna hyperparameter tuning\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 16, 128),\n",
        "        'max_depth': trial.suggest_int('max_depth', -1, 20),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 1.0),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 1.0),\n",
        "        'random_state': 42,\n",
        "        'force_col_wise': True,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "\n",
        "    model = LGBMRegressor(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    return mse  # Minimizing MSE\n",
        "\n",
        "# Run the study\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=40, show_progress_bar=True)\n",
        "\n",
        "# Retrieve best model\n",
        "best_params = study.best_params\n",
        "best_params['random_state'] = 42\n",
        "best_params['force_col_wise'] = True\n",
        "best_params['n_jobs'] = -1\n",
        "\n",
        "tuned_lgb = LGBMRegressor(**best_params)\n",
        "tuned_lgb.fit(X_train, y_train)\n",
        "y_pred_tuned = tuned_lgb.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "mse = mean_squared_error(y_test, y_pred_tuned)\n",
        "r2 = r2_score(y_test, y_pred_tuned)\n",
        "brier_score = mse\n",
        "\n",
        "print(\"=== Optuna Tuned LightGBM ===\")\n",
        "print(f\"Best Params: {best_params}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"Adapted Brier Score: {brier_score:.4f}\")"
      ],
      "metadata": {
        "id": "9X8QR7_cSerb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve best parameters and reinitialize tuned model\n",
        "best_params = study.best_params\n",
        "best_params['random_state'] = 42\n",
        "best_params['force_col_wise'] = True\n",
        "best_params['n_jobs'] = -1\n",
        "\n",
        "# Create and train final tuned model\n",
        "tuned_lgb = LGBMRegressor(**best_params)\n",
        "tuned_lgb.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate using the tuned model\n",
        "y_pred = tuned_lgb.predict(X_test)\n",
        "\n",
        "# Save predictions globally so all plots use tuned model\n",
        "y_pred_tuned = y_pred\n",
        "\n",
        "# === Evaluation After Optuna-Tuned Model ===\n",
        "train_pred = tuned_lgb.predict(X_train)\n",
        "test_pred = tuned_lgb.predict(X_test)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, train_pred)\n",
        "train_r2 = r2_score(y_train, train_pred)\n",
        "test_mse = mean_squared_error(y_test, test_pred)\n",
        "test_r2 = r2_score(y_test, test_pred)\n",
        "\n",
        "print(\"=== Evaluation: Optuna-Tuned LightGBM ===\")\n",
        "print(f\"Train R²: {train_r2:.4f}\")\n",
        "print(f\"Train MSE: {train_mse:.4f}\")\n",
        "print(f\"Train Brier Score (Adapted): {train_mse:.4f}\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Test R²: {test_r2:.4f}\")\n",
        "print(f\"Test MSE: {test_mse:.4f}\")\n",
        "print(f\"Test Brier Score (Adapted): {test_mse:.4f}\")\n"
      ],
      "metadata": {
        "id": "WQN7vj2RSphg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lightgbm feature importance\n",
        "# Prepare feature importance data\n",
        "feat_imp_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': tuned_lgb.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Keep only the top 15 features\n",
        "top_feat_imp_df = feat_imp_df.head(15).sort_values(by='Importance', ascending=True)\n",
        "\n",
        "# color palette\n",
        "colors = sns.color_palette(\"tab20\", n_colors=15)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "barplot = sns.barplot(\n",
        "    x='Importance',\n",
        "    y='Feature',\n",
        "    data=feat_imp_df,\n",
        "    palette=colors\n",
        ")\n",
        "\n",
        "# Annotate value on right end of each bar\n",
        "for i, (importance, feature) in enumerate(zip(feat_imp_df['Importance'], feat_imp_df['Feature'])):\n",
        "    plt.text(\n",
        "        importance + max(feat_imp_df['Importance']) * 0.01,  # slight offset\n",
        "        i,\n",
        "        f'{importance:,}',\n",
        "        va='center',\n",
        "        ha='left',\n",
        "        fontsize=10,\n",
        "        color='black'\n",
        "    )\n",
        "\n",
        "# Formatting\n",
        "plt.title('Feature Importances (Tuned LightGBM)', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Importance (Split Frequency)', fontsize=13)\n",
        "plt.ylabel('Feature', fontsize=13)\n",
        "plt.xticks(fontsize=11)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.grid(axis='x', linestyle='--', linewidth=0.5, alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qWoy93x-Sy72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recalculate SHAP values\n",
        "explainer = shap.Explainer(tuned_lgb, X_train)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# Define custom color palettes\n",
        "bar_color = sns.color_palette(\"deep\")[0]\n",
        "cmap_beeswarm = plt.get_cmap(\"coolwarm\")\n",
        "\n",
        "# SHAP Bar Plot\n",
        "mean_abs_shap = pd.DataFrame({\n",
        "    'Feature': X_test.columns,\n",
        "    'MeanAbsSHAP': np.abs(shap_values.values).mean(axis=0)\n",
        "}).sort_values(by='MeanAbsSHAP', ascending=True)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "bars = plt.barh(\n",
        "    y=mean_abs_shap['Feature'],\n",
        "    width=mean_abs_shap['MeanAbsSHAP'],\n",
        "    color=bar_color\n",
        ")\n",
        "\n",
        "# Annotate bars\n",
        "for bar in bars:\n",
        "    width = bar.get_width()\n",
        "    plt.text(width + max(mean_abs_shap['MeanAbsSHAP']) * 0.01, bar.get_y() + bar.get_height() / 2,\n",
        "             f'{width:.3f}', va='center', ha='left', fontsize=10)\n",
        "\n",
        "# Formatting\n",
        "plt.title(\"Top Features by Mean Absolute SHAP Value\\n(Tuned LightGBM)\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"Mean |SHAP Value| (Impact on Model Output)\", fontsize=13)\n",
        "plt.ylabel(\"Feature\", fontsize=13)\n",
        "plt.xticks(fontsize=11)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.grid(axis='x', linestyle='--', linewidth=0.5, alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Spacer between plots\n",
        "print(\"\\n\" * 3)\n",
        "\n",
        "# SHAP Beeswarm Plot\n",
        "# Custom plot title using matplotlib\n",
        "plt.figure(figsize=(12, 1))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"SHAP Beeswarm Plot of Top 20 Features\\n(Tuned LightGBM)\", fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Actual beeswarm plot\n",
        "shap.summary_plot(\n",
        "    shap_values,\n",
        "    X_test,\n",
        "    max_display=20,\n",
        "    plot_size=(12, 10),\n",
        "    color=cmap_beeswarm,\n",
        "    show=False\n",
        ")\n",
        "\n",
        "plt.ylabel(\"Feature\", fontsize=13, labelpad=15)\n",
        "plt.xlabel(\"SHAP Value (Impact on Model Output)\", fontsize=13)\n",
        "plt.xticks(fontsize=11)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.grid(axis='x', linestyle='--', linewidth=0.5, alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "suqrHIlBTc6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define feature groups for ablation test\n",
        "accounting_features = [\n",
        "    'loans', 'tier1', 'assets', 'int_income', 'int_expense', 'LDR',\n",
        "    'Tier1_to_Assets', 'Net_Interest_Margin', 'liquid_assets',\n",
        "    'assets.1', 'brokered_deposits', 'deposits',\n",
        "    'Liquid_to_Assets', 'Brokered_to_Deposits'\n",
        "]\n",
        "\n",
        "macro_features = [\n",
        "    'Regional_InflationRate', 'State_UnemploymentRate'\n",
        "]\n",
        "\n",
        "non_accounting_features = [\n",
        "    'Total_Employees', 'WARN_Layoffs', 'Layoffs_per_1000',\n",
        "    'Num_Layoff_Dates', 'Avg_Notice_to_Layoff_Days',\n",
        "    'Sentiment_of_Failure'\n",
        "]\n",
        "\n",
        "# preserve quarter since it was in model training\n",
        "quarter_col = ['Quarter']"
      ],
      "metadata": {
        "id": "k4H06qT0Trc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accounting_features = [\n",
        "    'loans', 'tier1', 'assets', 'int_income', 'int_expense', 'LDR',\n",
        "    'Tier1_to_Assets', 'Net_Interest_Margin', 'liquid_assets',\n",
        "    'assets.1', 'brokered_deposits', 'deposits',\n",
        "    'Liquid_to_Assets', 'Brokered_to_Deposits'\n",
        "]\n",
        "\n",
        "macro_features = [\n",
        "    'Regional_InflationRate', 'State_UnemploymentRate'\n",
        "]\n",
        "\n",
        "non_accounting_features = [\n",
        "    'Total_Employees', 'WARN_Layoffs', 'Layoffs_per_1000',\n",
        "    'Num_Layoff_Dates', 'Avg_Notice_to_Layoff_Days',\n",
        "    'Sentiment_of_Failure'\n",
        "]\n",
        "\n",
        "# Ablation Feature Sets\n",
        "feature_sets = {\n",
        "    'Accounting Only': accounting_features,\n",
        "    'Accounting & Macro': accounting_features + macro_features,\n",
        "    'Full Features': accounting_features + macro_features + non_accounting_features\n",
        "}\n",
        "ordered_labels = ['Accounting Only', 'Accounting & Macro', 'Full Features']\n",
        "\n",
        "# Compute R² with cloned tuned model\n",
        "ablation_results = {}\n",
        "for label in ordered_labels:\n",
        "    selected_features = feature_sets[label]\n",
        "    X_train_ab = X_train[selected_features]\n",
        "    X_test_ab = X_test[selected_features]\n",
        "\n",
        "    ab_model = clone(tuned_lgb)\n",
        "    ab_model.fit(X_train_ab, y_train)\n",
        "    y_pred_ab = ab_model.predict(X_test_ab)\n",
        "\n",
        "    ab_r2 = r2_score(y_test, y_pred_ab)\n",
        "    ablation_results[label] = ab_r2\n",
        "\n",
        "# Format Results for Plot\n",
        "ablation_df = pd.DataFrame({\n",
        "    'Feature Set': ordered_labels,\n",
        "    'R2': [ablation_results[label] for label in ordered_labels]\n",
        "})\n",
        "\n",
        "# Plot\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "colors = sns.color_palette(\"tab20\")[:3]  # First 3 solid colors\n",
        "\n",
        "barplot = sns.barplot(\n",
        "    data=ablation_df,\n",
        "    x='Feature Set',\n",
        "    y='R2',\n",
        "    palette=colors,\n",
        "    order=ordered_labels\n",
        ")\n",
        "\n",
        "# Annotate R² inside each bar\n",
        "for i, row in ablation_df.iterrows():\n",
        "    plt.text(\n",
        "        x=i,\n",
        "        y=row.R2 / 2,\n",
        "        s=f\"{row.R2:.3f}\",\n",
        "        ha='center',\n",
        "        va='center',\n",
        "        fontsize=12,\n",
        "        color='white' if row.R2 > 0.5 else 'black',\n",
        "        fontweight='bold'\n",
        "    )\n",
        "\n",
        "# Final formatting\n",
        "plt.title(\"Ablation Study: Predictive Contribution of Feature Groups\", fontsize=16, fontweight='bold')\n",
        "plt.ylabel(\"R² Score (Test Set)\", fontsize=13)\n",
        "plt.xlabel(\"Feature Group\", fontsize=13)\n",
        "plt.ylim(0, max(ablation_df['R2']) + 0.1)\n",
        "plt.xticks(fontsize=11)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.grid(axis='y', linestyle='--', linewidth=0.6, alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wLfkryd_TtfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use tuned LightGBM from earlier\n",
        "models = {\n",
        "    'Tuned LightGBM': tuned_lgb,\n",
        "    'Random Forest': RandomForestRegressor(random_state=42),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'XGBoost': XGBRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "print(\"=== Model Benchmarking ===\")\n",
        "for name, model in models.items():\n",
        "    # Only retrain if not already tuned\n",
        "    if name != 'Tuned LightGBM':\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    brier = mse  # Adapted Brier = MSE in regression\n",
        "\n",
        "    print(f\"{name} -> MSE: {mse:.4f}, R²: {r2:.4f}, Brier: {brier:.4f}\")"
      ],
      "metadata": {
        "id": "wBFoBgslT9c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare results\n",
        "results = {\n",
        "    'Model': [],\n",
        "    'R2 Score': [],\n",
        "    'MSE': []\n",
        "}\n",
        "\n",
        "# Compute scores using predefined 'models' dict\n",
        "for name, model in models.items():\n",
        "    if name != 'Tuned LightGBM':\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "    results['Model'].append(name)\n",
        "    results['R2 Score'].append(r2_score(y_test, preds))\n",
        "    results['MSE'].append(mean_squared_error(y_test, preds))\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Plotting Setup\n",
        "sns.set(style=\"whitegrid\")\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6), dpi=100)\n",
        "\n",
        "colors = sns.color_palette(\"tab20\")[:len(results_df)]\n",
        "\n",
        "# R² Score Plot\n",
        "sns.barplot(\n",
        "    ax=axes[0],\n",
        "    data=results_df,\n",
        "    x='Model',\n",
        "    y='R2 Score',\n",
        "    palette=colors\n",
        ")\n",
        "axes[0].set_title(\"Model Comparison: R² Score\", fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylim(0, 1)\n",
        "axes[0].set_ylabel(\"R² Score\", fontsize=12)\n",
        "axes[0].set_xlabel(\"\")\n",
        "axes[0].tick_params(axis='x', rotation=20)\n",
        "for i, row in results_df.iterrows():\n",
        "    axes[0].text(i, row['R2 Score'] + 0.02, f\"{row['R2 Score']:.3f}\", ha='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "#sns.barplot(\n",
        "    ax=axes[1],\n",
        "    data=results_df,\n",
        "    x='Model',\n",
        "    y='MSE',\n",
        "    palette=colors\n",
        "\n",
        "axes[1].set_title(\"Model Comparison: Mean Squared Error\", fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel(\"MSE (Lower is Better)\", fontsize=12)\n",
        "axes[1].set_xlabel(\"Model\", fontsize=12)\n",
        "axes[1].tick_params(axis='x', rotation=20)\n",
        "for i, row in results_df.iterrows():\n",
        "    axes[1].text(i, row['MSE'] * 1.02, f\"{row['MSE']:.4f}\", ha='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Final Formatting\n",
        "plt.suptitle(\"Model Performance Comparison\", fontsize=16, fontweight='bold')\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TFfW6g6wUBYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#AUROC Plot\n",
        "# Binarize Target\n",
        "threshold = 0.5\n",
        "y_test_binary = (y_test >= threshold).astype(int)\n",
        "\n",
        "# Define Models\n",
        "models = {\n",
        "    'Tuned LightGBM': tuned_lgb,\n",
        "    'Random Forest': RandomForestRegressor(random_state=42),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'XGBoost': XGBRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "# Compute ROC/AUC\n",
        "roc_results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name not in ['Tuned LightGBM', 'Tuned XGBoost']:\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    # Normalize for Ridge\n",
        "    if name == \"Ridge Regression\":\n",
        "        preds = (preds - preds.min()) / (preds.max() - preds.min())\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_test_binary, preds)\n",
        "    auc = roc_auc_score(y_test_binary, preds)\n",
        "    roc_results[name] = (fpr, tpr, auc)\n",
        "\n",
        "# Plot Setup\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(10, 7), dpi=110)\n",
        "colors = sns.color_palette(\"tab20\", n_colors=len(roc_results))\n",
        "\n",
        "# Plot ROC Curves\n",
        "for i, (name, (fpr, tpr, auc)) in enumerate(roc_results.items()):\n",
        "    plt.plot(\n",
        "        fpr, tpr,\n",
        "        label=f\"{name} (AUC = {auc:.3f})\",\n",
        "        linewidth=2.5,\n",
        "        linestyle='-' if 'Tuned' in name else '--',\n",
        "        color=colors[i]\n",
        "    )\n",
        "\n",
        "# Reference diagonal\n",
        "plt.plot([0, 1], [0, 1], 'k--', linewidth=1.2, label=\"Random Classifier\")\n",
        "\n",
        "# Formatting\n",
        "plt.title(\"ROC Curve Comparison Across Models\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"False Positive Rate\", fontsize=13)\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=13)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.grid(True, linestyle='--', linewidth=0.6, alpha=0.7)\n",
        "\n",
        "# Legend\n",
        "plt.legend(loc='lower right', fontsize=11, frameon=True, edgecolor='black')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D-pniUQerjD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit untuned baseline models\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "ridge_model = Ridge()\n",
        "xgb_model = XGBRegressor(random_state=42)\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Exclude Quarter Feature\n",
        "exclude_features = [\"Quarter\"]\n",
        "\n",
        "# Extract top N features\n",
        "def get_top_features(importances, feature_names, top_n=10):\n",
        "    df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "    df = df[~df['Feature'].isin(exclude_features)]\n",
        "    df = df.sort_values(by='Importance', ascending=False).head(top_n)\n",
        "    return df\n",
        "\n",
        "# Ridge Regression\n",
        "ridge_importances = np.abs(ridge_model.coef_)\n",
        "ridge_df = get_top_features(ridge_importances, X_train.columns)\n",
        "\n",
        "# Random Forest\n",
        "rf_df = get_top_features(rf_model.feature_importances_, X_train.columns)\n",
        "\n",
        "# Tuned LightGBM\n",
        "lgb_df = get_top_features(tuned_lgb.feature_importances_, tuned_lgb.feature_name_)\n",
        "\n",
        "# XGBoost\n",
        "xgb_df = get_top_features(xgb_model.feature_importances_, xgb_model.feature_names_in_)\n",
        "\n",
        "# Plot Setup\n",
        "sns.set(style=\"whitegrid\")\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10), dpi=110)\n",
        "fig.suptitle(\"Top 10 Feature Importances Across Models\", fontsize=18, fontweight='bold')\n",
        "\n",
        "color_palette = sns.color_palette(\"tab20\", n_colors=10)\n",
        "\n",
        "# Plotting Function\n",
        "def plot_importance_bar(ax, df, title):\n",
        "    sns.barplot(\n",
        "        ax=ax,\n",
        "        x=\"Importance\",\n",
        "        y=\"Feature\",\n",
        "        data=df,\n",
        "        palette=color_palette\n",
        "    )\n",
        "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel(\"Importance\", fontsize=12)\n",
        "    ax.set_ylabel(\"\")\n",
        "    ax.tick_params(labelsize=11)\n",
        "\n",
        "    for i, (val, _) in enumerate(zip(df[\"Importance\"], df[\"Feature\"])):\n",
        "        ax.text(val * 1.01, i, f\"{val:.3f}\", va='center', fontsize=10)\n",
        "\n",
        "# Create Each Plot\n",
        "plot_importance_bar(axes[0, 0], ridge_df, \"Ridge Regression (|Coefficients|)\")\n",
        "plot_importance_bar(axes[0, 1], rf_df, \"Random Forest (Gini Importance)\")\n",
        "plot_importance_bar(axes[1, 0], lgb_df, \"Tuned LightGBM (Split Gain)\")\n",
        "plot_importance_bar(axes[1, 1], xgb_df, \"XGBoost (Gain)\")\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6NmvSsYztn8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spearman Rank Correlation Coefficient Bar Chart\n",
        "# Refit Untuned Models\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "ridge_model = Ridge()\n",
        "xgb_model = XGBRegressor(random_state=42)\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions from all models\n",
        "predictions = {\n",
        "    \"Tuned LightGBM\": tuned_lgb.predict(X_test),\n",
        "    \"XGBoost\": xgb_model.predict(X_test),\n",
        "    \"Random Forest\": rf_model.predict(X_test),\n",
        "    \"Ridge Regression\": ridge_model.predict(X_test)\n",
        "}\n",
        "\n",
        "# Compute Spearman ρ\n",
        "spearman_scores = {\n",
        "    model: spearmanr(pred, y_test).correlation\n",
        "    for model, pred in predictions.items()\n",
        "}\n",
        "\n",
        "# Format as DataFrame\n",
        "spearman_df = pd.DataFrame.from_dict(spearman_scores, orient='index', columns=[\"Spearman ρ\"])\n",
        "spearman_df = spearman_df.sort_values(by=\"Spearman ρ\", ascending=False)\n",
        "\n",
        "# Define custom colormap\n",
        "pastel_colors = sns.color_palette(\"BuGn\", 20)\n",
        "pastel_cmap = ListedColormap(pastel_colors)\n",
        "\n",
        "# Plot\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(6, 4), dpi=110)\n",
        "\n",
        "ax = sns.heatmap(\n",
        "    spearman_df,\n",
        "    annot=True,\n",
        "    cmap=tab20_cmap,\n",
        "    fmt=\".3f\",\n",
        "    linewidths=0.7,\n",
        "    cbar_kws={\n",
        "        'label': 'Spearman Rank Correlation (ρ)',\n",
        "        'shrink': 0.8,\n",
        "        'orientation': 'vertical'\n",
        "    },\n",
        "    annot_kws={\"size\": 11, \"weight\": \"bold\"}\n",
        ")\n",
        "\n",
        "# Title and axes\n",
        "ax.set_ylabel(\"Model\", fontsize=12, labelpad=10)\n",
        "plt.title(\"Spearman Rank Correlation: Predictions vs. True Risk Scores\", fontsize=14, fontweight='bold', pad=14)\n",
        "plt.xticks(rotation=0, fontsize=11)\n",
        "plt.yticks(rotation=0, fontsize=11)\n",
        "ax.figure.axes[-1].yaxis.label.set_size(12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hqjUnI1SvSrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision@K function\n",
        "def precision_at_k(y_true, y_pred, k):\n",
        "    pred_top_k = np.argsort(y_pred)[-k:][::-1]\n",
        "    true_top_k = np.argsort(y_true)[-k:][::-1]\n",
        "    return len(set(pred_top_k) & set(true_top_k)) / k\n",
        "\n",
        "# Define K values\n",
        "k_values = [5, 10, 20]\n",
        "\n",
        "# Collect predictions\n",
        "predictions = {\n",
        "    \"Tuned LightGBM\": tuned_lgb.predict(X_test),\n",
        "    \"XGBoost\": xgb_model.predict(X_test),\n",
        "    \"Random Forest\": rf_model.predict(X_test),\n",
        "    \"Ridge Regression\": ridge_model.predict(X_test)\n",
        "}\n",
        "\n",
        "# Compute Precision@K\n",
        "precision_records = []\n",
        "for k in k_values:\n",
        "    for model_name, preds in predictions.items():\n",
        "        score = precision_at_k(y_test.values, preds, k)\n",
        "        precision_records.append({\n",
        "            \"Model\": model_name,\n",
        "            \"K\": f\"@{k}\",\n",
        "            \"Precision@K\": score\n",
        "        })\n",
        "\n",
        "precision_df = pd.DataFrame(precision_records)\n",
        "\n",
        "# Plotting\n",
        "sns.set(style=\"whitegrid\")\n",
        "tab20_colors = sns.color_palette(\"tab20\", len(predictions))\n",
        "\n",
        "plt.figure(figsize=(10, 6), dpi=120)\n",
        "ax = sns.barplot(\n",
        "    data=precision_df,\n",
        "    x=\"Model\",\n",
        "    y=\"Precision@K\",\n",
        "    hue=\"K\",\n",
        "    palette=tab20_colors[:len(k_values)]\n",
        ")\n",
        "\n",
        "# Label bars\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt=\"%.2f\", padding=3, fontsize=10, weight='bold')\n",
        "\n",
        "# Formatting\n",
        "plt.title(\"Precision@K: Top-K Risk Ranking Accuracy Across Models\", fontsize=15, fontweight='bold', pad=14)\n",
        "plt.xlabel(\"Model\", fontsize=13)\n",
        "plt.ylabel(\"Precision@K\", fontsize=13)\n",
        "plt.ylim(0, 1.05)\n",
        "plt.xticks(rotation=10, fontsize=11)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.legend(title=\"Top-K\", title_fontsize=12, fontsize=11, loc='upper right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1kRKEVF1yGDf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}